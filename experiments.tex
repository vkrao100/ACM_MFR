\section{Experimental Results}
\label{sec:exp}

% \begin{table}[hbt!]
% \centering
% \caption{{\footnotesize Synthesis results for mapped patch network; $\textit{I}$ = Benchmark Index, GFC = Greedy function computation,
% DFC = Function computation with don't cares, $A$ = Area, $D$ = Delay, '-' - SIS core dumped while performing optimization}}
% \label{tab:fun_synth}
% \resizebox{\linewidth}{!}{
% \begin{tabular}
% {!{\vrule width 1pt} c !{\vrule width 1pt} c | c !{\vrule width 1pt} c | c !{\vrule width 1pt} c | c !{\vrule width 1pt} c | c !{\vrule width 1pt} c | c !{\vrule width 1pt} c | c !{\vrule width 1pt}}\noalign{\hrule height 1pt}
% \multicolumn{1}{!{\vrule width 1pt} c !{\vrule width 1pt}}{} & \multicolumn{4}{ c !{\vrule width 1pt}}{Mastrovito} & \multicolumn{4}{ c !{\vrule width 1pt}}{Montgomery} & \multicolumn{4}{ c !{\vrule width 1pt}}{Point Addition}\\ \noalign{\hrule height 1pt}
% \multicolumn{1}{!{\vrule width 1pt} c !{\vrule width 1pt}}{} & \multicolumn{2}{ c !{\vrule width 1pt}}{GFC} & \multicolumn{2}{ c !{\vrule width 1pt}}{DFC}& \multicolumn{2}{ c !{\vrule width 1pt}}{GFC}& \multicolumn{2}{ c !{\vrule width 1pt}}{DFC}& \multicolumn{2}{ c !{\vrule width 1pt}}{GFC}& \multicolumn{2}{ c !{\vrule width 1pt}}{DFC}\\ \noalign{\hrule height 1pt}
% $\textit{I}$ & {$A$} & {$D$} & {$A$} & {$D$} & {$A$} & {$D$}  & {$A$} & {$D$} & {$A$} & {$D$} & {$A$} & {$D$} \\ \noalign{\hrule height 1pt}
% 1  & 19   & 3  & 179 & 30 & 19   & 3  & 108  & 16 & 27788 & 50 & -     & -  & 27819 & 38 & -    & -  & 761   & 40 & 605  & 24 & 769  & 37 & 523  & 23 \\ \hline
% 2  & 34   & 5  & 35  & 4  & 34   & 4  & 35   & 5  & 19340 & 65 & -     & -  & 19110 & 73 & -    &    & 8882  & 69 & 9508 & 61 & 8652 & 61 & 9796 & 65 \\ \hline
% 3  & 1675 & 29 & 1628& 40 & 1562 & 27 & 1578 & 45 & 1511  & 30 & 839   & 24 & 1389  & 28 & 1540 & 42 & 3040  & 32 & 3733 & 41 & 2776 & 29 & 3438 & 40 \\ \hline
% 4  & 86   & 11 & 67  & 14 & 94   & 11 & 76   & 14 & 55085 & 50 & -     & -  & 43957 & 48 & -    & -  & 6642  & 89 & 6098 & 75 & 6597 & 84 & 6108 & 76 \\ \hline
% 5  & 283  & 21 & 109 & 12 & 215  & 17 & 103  & 12 & 25819 & 44 & 26744 & 35 & -     & -  & -    & -  & 27544 & 36 & -    & -  & -    & -  & -    & -  \\ \hline
% 6  & 222  & 17 & 238 & 17 & 148  & 13 & 217  & 25 & 27035 & 68 & -     & -  & -     & -  & -    & -  & 66    & 8  & 49   & 9  & 52   & 10 & 59   & 16 \\ \hline
% 7  & 9    & 4  & 9   & 4  & 9    & 4  & 9    & 4  & 8094  & 25 & 4948  & 28 & 6413  & 23 & 9418 & 30 & 4345  & 30 & 5169 & 34 & 4825 & 28 & 4935 & 35 \\ \hline
% 8  & 16   & 4  & 16  & 4  & 16   & 4  & 16   & 4  & 844   & 13 & 4     & 2  & 844   & 13 & 4    & 2  & 2707  & 24 & -    & -  &  -   & -  & -    & -  \\ \hline
% 9  & 21   & 7  & 21  & 6  & 21   & 7  & 21   & 6  & -     & -  & -     & -  & -     & -  & -    & -  & 622   & 22 & 210  & 16 & 486  & 24 & 210  & 16 \\ \noalign{\hrule height 1pt}
% \end{tabular}}
% \vspace{- 0.25in}  
% \end{table}

% {\it implicit} characteristic set representation 
% for storing and manipulating polynomials. 
% The same framework 
% is utilized towards implementing incremental rectification check.
% Our implementation utilizes PolyBoriâ€™s~\cite{pbori:JSC09} reduction procedure with 
% ZDD~\cite{Minato:DAC93,Minato:DAC94} as the underlying data structure to 
% model the MFR framework. 
% % Our rectification approach operates 
% % over the ring $\ftkwring$, whereas ZDDs can only be used 
% % to represent polynomials and perform reductions in $\ftring$.
% % % We extend these operations to accommodate the sum and product operations
% % % $\pmod{2}$, i.e. polynomial algebra in $\Ftwo[x_1,\dots,x_d]$, by 
% % % manipulating sets of combinations using ZDDs. 
% % However, as the core of our computations is based on a
% % couple of Spoly reductions, it is possible to employ ZDDs
% % ~\cite{Utkarsh:TCAD19}. 
% Taking inspiration from~\cite{Utkarsh:TCAD19}, we make use of the 
% {\it implicit} characteristic set representation 
% for storing and manipulating polynomials. 
% % The same framework 
% % is utilized towards implementing incremental rectification check.
% In addition, we have developed a high level finite field engine
%  to model bit-vector and coefficient computations.
% Further, we have also utilized polynomial algebra tool {\sc Singular}
% ~\cite{DGPS_410} for finding primitive polynomials to help model composite field characteristics.
% PAD - 14000 s - 409 - 54279665 multiplications
% PAD  - 2237 s - 409 - 7363636 multiplications
% PAD - 3482 - 571 - 2189802 multiplications
% Subject to the given variable order, a ZDD represents a 
% Boolean function canonically. Just as with BDDs, every node in a ZDD
% is assigned an index, which corresponds to the variable order imposed
% on the diagram. A detailed description of ZDDs and
% their capabilities for solving logic optimization and sparse
% combinatorial problems can be found in \cite{Minato:DAC93} and
% \cite{Minato:DAC94}. 
% Minato has shown ([94][95]) how the set union, intersection and difference operations
% can be performed recursively on the ZDDs, and they have been implemented using the
% ite-operator (if-then-else) in decision diagrams such as the CUDD [118] package. We extend
% these operations to accommodate the sum and product operations ( mod 2 ) , i.e. polyno-
% mial algebra in F 2 [ x 1 ,...,x n ] , by manipulating sets of combinations using ZDDs.
% Based on the above discussion, we will: i) model GBR as the algebra of unate cube
% sets; ii) use ZDDs as the implicit data-structure for this GBR; and iii) devise efficient
% implementation of GBR by exploiting the special structure imposed by RTTO on the ZDD
% graph.where each unate cube (monomial) represents one combination,
%and each literal represents an object chosen in the combination.
% -- resembling a
%classical logic synthesis problem. 
%Then the ZDD can also be used to represent
%polynomials where the monomials can be obtained the same way the cubes
%are obtained for the equivalent set. 
% Once verification detects presence of bugs, we use heuristics (Section.~\ref{subsec:target_nets})  
% to identify targets for MFR. Following this, we apply Thm.~\ref{Thm:rect} to perform rectification check. Once rectification check passes, we apply the approach described in Section VI of Rao et al.~\cite{Vkrao:FMCAD18} to compute 
% a rectification function.
% In the result tables, the rows marked with an '*' indicate that the patch size $m$ is 
% such that $m \nmid n$, hence requiring operations in composite field $\Fkk$, where $k = LCM(m,n)$.
 % IC = Incremental rectification check,



The benchmark suit includes two modular multipliers (Mastrovito and Montgomery), and 
a circuit that performs Point Addition over NIST standard Elliptic curves.
These benchmarks are taken from~\cite{lv:tcad2013} and synthesized using the {\it abc} tool 
with a gate library comprising two input gates.~\autoref{exptbl} presents the results 
of our approach when performing MFR against their respective polynomial specifications. 
We introduce bugs by means of gate and wiring modifications in the synthesized 
netlists such that multiple output bits are affected in the design (column \#BO). 
% Since these benchmarks are structurally concise, we place each bug
%  in a redundant logic to introduce don't care conditions in the design.
% We introduce multiple such buggy redundant logics at various topological levels: 
We introduce multiple such modifications at various topological levels:
some closer to PIs, some in the middle of the circuit, and some near POs. 
In our experiments, the number of targets is 
chosen from $m=\{2,3,5\}$. 
Our approach isn't limited by this set $m$ and can perform MFR
for any given number of targets.
% A reasonable measure of a difficult problem instance can be obtained by observing 
% the total number of affected outputs (BO) in~\autoref{exptbl} and the corresponding 
% patch size computed in~\autoref{tab:func_synth}.
% A measure of the complexity of the problem instance can be identified by
% observing the total number of  outputs (\#BO) in~\autoref{exptbl} coupled with 
% the size of the corresponding patch computation in~\autoref{tab_func_synth}. 
% The total number of affected outputs by the bugs coupled with 

% All the algorithms and computations were implemented in Polybori engine~\cite{pbori:JSC09}.
% Our implementation is based on 
% Based on the above discussion, we will: i) model GBR as the
% algebra of unate cube sets; ii) use ZDDs as the implicit
% data-structure for this GBR; and iii) devise efficient implementation
% of GBR by exploiting the special structure imposed by RTTO on the
% ZDD graph.  
% In \cite{Minato:DAC94}, {\it Minato} demonstrated that ZDDs are an
% efficient data-structure for implicit manipulation (algebra) of unate
% cube sets. 
%Since a monomial of a Boolean
%polynomial is a unate cube, we can interpret a Boolean polynomial as a
%set of unate cubes; and each monomial (cube) as a set of
%variables. 
% {\it Minato} has shown (\cite{Minato:DAC93}\cite{Minato:DAC94}) how the set union, intersection and
% difference operations can be performed recursively on the ZDDs, 
% and they have been implemented using the {\it ite-operator (if-then-else)} in
% decision diagrams such as the CUDD \cite{Somenzi:CUDD} package. 
% By analyzing the {structure of ZDDs} for 
% polynomial representation, we show how this 
% GB-reduction can be efficiently implemented using algorithms that
% specifically manipulate the ZDD graph. 
Our approach is implemented as a custom software in Python programming language. 
We use PolyBori's~\cite{pbori:JSC09} ZDD based API to implement the division, 
$f\xrightarrow{F'_l\cup F'_{0}}_+ rem_l,$ $ 1 \leq l \leq 2^m$. Subsequently, 
the remainders generated from these divisions are utilized in the decision procedure, 
as well as the function computations.
Further, we use {\it sis}~\cite{SIS92} and {\it abc}~\cite{abc} to perform 
logic optimization and synthesis. Specifically, in {\it sis} we run a 
script to perform {\it kernel extraction} and {\it full simplify} to optimize the 
rectification functions computed in Sec.\ref{comp:DFC1}. We use {\it abc}
to perform {\it structural hashing, balancing, refactoring, rewriting, etc.}.
Finally, we {\it map} the computed functions using a library of AND-XOR-INV gates and extract
the synthesis results for {\it area} and {\it delay}. The experiments are performed on a 3.5GHz 
Intel(R) $\text{Core}^{\text{TM}}$ i7-4770K Quad-Core CPU with 32 GB RAM.

~\autoref{exptbl} presents the characteristics of the benchmark 
suit and the execution time for the computations using our approach.
Column PBS denotes the time taken to build the respective ZDD 
models (commensurates with the operand word-length $n$).
% RC denotes the time to generate the remainders and 
% perform a rectification check. 
Execution time for rectification check (RC) and function computation (GFC and DFC) 
depend on various factors such as: i) the number of bugs; ii) the number of targets;
iii) location of the bugs; iv) location of the targets; v) the number of affected outputs;
and vi) size of the patch function being computed in terms of number of gates. 
Collectively, these factors decide the size of the remainder $rem_l$, and the
number of remainders $l$. 
% Larger the size, the longer it takes to compute the function.
% The time taken for function computations (GFC and DFC) is dependent on 
% the size of the patch function being computed, which in turn depends 
% on the size of the remainders $rem_l$.
% Larger the size, the longer it takes to compute the function.
We omit the comparison with the contemporary approaches as they
fail (timeout = 3 hrs) to rectify circuits beyond 16-bits,
which is the smallest benchmark from our results table. 
% Our approach isn't compared with the contemporary approaches as they
% fail to rectify the circuits beyond 16-bit operand word length (smallest )

\autoref{tab_func_synth} presents the synthesis results post {\it abc} mapping 
for GFC and DFC approaches in terms of area (number of gates)
and the longest topological delay. The asterisk (*) in the DFC columns denotes the 
cases where {\it full simplify} ({\it sis}) fails to utilize the 
pairwise intersection don't care network for the on-set function simplification.
 In these cases, {\it sis} aborts simplification as the
 BDD size exceeds 480,000 nodes. For these entries, the patch functions
 are synthesized using {\it abc} which ignores the don't care network.
The time taken for GFC is less than the time taken for DFC computations.
However, synthesis results computed using DFC where {\it sis} completed
simplification successfully are of better quality than
the one computed using GFC for most of the cases.  
% As seen from the results table, for most of the cases where {\it sis} completed
% simplification successfully, the synthesis results using DFC approach is better 
% than the corresponding synthesis result computed using the greedy approach.

% The rectification functions computed using the greedy approach 
% are synthesized using {\it abc}, while the functions computed along with don't cares 
% uses {\it sis} for logic optimization using don't cares before synthesizing .

% We compare our approach against the cofactor reduction algorithm (Alg. 1) 
% presented in~\cite{MF_Huang:DATE12}. We implemented the Alg. 1 of~\cite{MF_Huang:DATE12} 
% using {\it abc/MiniSAT}. However, rectification check for circuits beyond 16-bits 
% timed out (3 hours) during the final UNSAT check on these benchmarks and hence the 
% comparison is omitted. The latter half of the table (index 10-15) presents results 
% when the chosen targets do not admit rectification.

% Once again we observe that the rectification function synthesized from
% ON-set and DC-set is no worse than that synthesized from ON-set alone for most experiments 
% except for $k=128$. 
% The difference in the synthesis results for
% the two rectification functions when DC-set is empty is due to the different synthesis algorithms 
% in {\it sis} and {\it abc}. The symbol $^\dagger$ in Table \ref{tab:Mas_NO} denotes that {\it simplification}
% using BDDs in {\it sis} is not performed (it was automatically aborted by {\it sis}) due to the size of BDDs exceeding 480,000 nodes.
% In the experiments, the ON-set
% and OFF-set functions ($ON$ and $OFF$, respectively) are optimized separately in {\it abc}, 
% and then the DC-set function is computed as $\neg(ON \vee OFF)$ (which is then provided to {\it sis} along with $ON$). 
% 
% For Mastrovito and Montgomery multipliers, the specification 
% polynomial is given as $f: = A\times B \pmod{ P_n(X)}$, 
% where $P_n(x)$ is a given primitive polynomial for the datapath size $n$. 
% In mastrovito architecture, the product $A \times B$ is computed using an 
% array multiplier architecture, and then the result is reduced modulo $P(X)$.
% Montgomery architectures are considered more efficient than Mastrovito for exponentiation, 
% as they do not require explicit reduction modulo $P(X)$ after each step. 
% The Point addition block implements operations required for the task of encryption, 
% decryption and authentication in Elliptic Curve Cryptography (ECC). 
% Modern approaches represent the points in projective
% coordinate systems, {\it e.g.}, the L$\acute{o}$pez-Dahab (LD) projective coordinate, 
% due to which the point addition operation can be implemented as polynomials in the field.
% The results table demonstrates the application of our approach towards
% checking the MFR in the most complex Point addition implementation block against
% its specification $D= B^2\cdot(C + aZ_1^2)$. 
\section{Conclusion}\label{sec:conc}
This paper presents an automated symbolic computer algebra approach to 
perform MFR of faulty finite field arithmetic circuits at a given set of targets.
Our approach reasons about the rectification functions by means of
algebraic varieties in finite fields, and computes these functions
using \Grobner bases of ideals corresponding to the circuit. 
We present two MFR approaches, a heuristic which greedily tries to
resolve the rectification functions for the targets, and 
a variety intersection heuristic that explores a subset of 
don't cares condition for the target functions. Our approach is
able to compute rectification functions for circuits with large
(NIST-standard) operand widths $n$. 
% utilizes \Grobner basis techniques as a properties to solve polynomial
% decision and quantification 
As part of future work, we are working on function computation in
terms of internal nets. Further, we are also investigating the
extension of this approach to integer arithmetic circuits.

% This paper presents an automated symbolic computer algebra approach to 
% perform MFR of faulty finite field arithmetic circuits at a given set of targets.
% Our approach models computation of rectification function as a quantification procedure.
% We present two approaches i) a greedy heuristic which tries to minimize the on-set function
% of the targets; ii) a pairwise intersection heuristic to explore and compute a subset of
% of don't cares along with an on-set and off-set for the targets.
% % utilizes \Grobner basis techniques as a properties to solve polynomial
% % decision and quantification 
% As part of our future work, we are working on function computation in terms of internal nets. 
% Further, we are also investigating the extension of this approach to integer arithmetic circuits. 
% \vspace{-0.18in}

% The underlying theory and algorithms are based on \Grobner 
% basis reductions, the Strong Nullstellensatz principle, 
% ideal membership testing, and finite fields.
% The efficiency our approach is derived by interpreting the targets 
% as a bit-vector and enabling word-level reasoning.
% We propose new mathematical insights to overcome the
% challenges associated with formulating the problem over a composite field.
% Experimental results demonstrate the efficacy of our approach
% against contemporary techniques. 
% As future work, we are
% investigating subsequent computation of multi-fix rectification 
% functions, also at the word-level. Further, we are also exploring
% techniques to improve the efficiency of rectification check implementation.
% Should we mention word level something?
% Should we not re-acronymize MFR?
% This paper presents an automated MFR check approach to of buggy finite field arithmetic circuits
% the ully automated symbolic computer algebra approach towards.
% %n order to compute a desired patch function, we need to account for the 
% % following key synthesis aspects in our rectification formulation:
% % \bi
% % \item 
% % \item Computing rectification functions in terms of internal nets.
% % % \item Selection of the rectification targets.
% % \ei
% % The gates of the circuit C are modeled as a set of polynomials where the variables 
% % are the nets of the circuit. An order on the variables is derived from 
% % the topology of the circuit, and a lex term order (RTTO $>$) is imposed on the polynomials. 
% Given a specification, a buggy circuit implementation, and a set of $m$-target nets,
% we perform rectifibility check at these nets. 
% The underlying theory and algorithms are based on \Grobner basis reductions, Nullstellensatz, and ideal membership test.  
% The experimental results demonstrate the efficacy of our approach for finite field 
% arithmetic circuits. 

\begin{table}[hbt]
\centering
\caption{{\footnotesize Synthesis results for mapped patch network; $\textit{I}$ = Benchmark Index, GFC = Greedy function computation,
DFC = Function computation with don't cares, $A$ = Area in terms of number of gates , $D$ = Longest delay} }
\label{tab_func_synth}
\resizebox{\linewidth}{!}{
\begin{tabular}
{!{\vrule width 1pt} c !{\vrule width 1pt} c | c !{\vrule width 1pt} c | c !{\vrule width 1pt} c | c !{\vrule width 1pt} c | c !{\vrule width 1pt} c | c !{\vrule width 1pt} c | c !{\vrule width 1pt}}\noalign{\hrule height 1pt}
\multicolumn{1}{!{\vrule width 1pt} c !{\vrule width 1pt}}{} & \multicolumn{4}{ c !{\vrule width 1pt}}{Mastrovito} & \multicolumn{4}{ c !{\vrule width 1pt}}{Montgomery}&\multicolumn{4}{ c !{\vrule width 1pt}}{Point Addition}\\ \noalign{\hrule height 1pt}
\multicolumn{1}{!{\vrule width 1pt} c !{\vrule width 1pt}}{} & \multicolumn{2}{ c !{\vrule width 1pt}}{GFC} & \multicolumn{2}{ c !{\vrule width 1pt}}{DFC}& \multicolumn{2}{ c !{\vrule width 1pt}}{GFC}& \multicolumn{2}{ c !{\vrule width 1pt}}{DFC}& \multicolumn{2}{ c !{\vrule width 1pt}}{GFC}& \multicolumn{2}{ c !{\vrule width 1pt}}{DFC}\\ \noalign{\hrule height 1pt}
$\textit{I}$ & {$A$} & {$D$} & {$A$} & {$D$} & {$A$} & {$D$}& {$A$} & {$D$} & {$A$} & {$D$} & {$A$} & {$D$} \\ \noalign{\hrule height 1pt}
1  & 19   & 3  & 17  & 3  & 27788 & 50 & 27941* & 62* & 761   & 40 & 265   & 12  \\ \hline
2  & 34   & 5  & 35  & 4  & 19340 & 65 & 19384* & 57* & 8882  & 69 & 9063* & 60* \\ \hline
3  & 1675 & 29 & 1577& 46 & 1511  & 30 & 560    & 18  & 3040  & 32 & 3733  & 41  \\ \hline
4  & 86   & 11 & 21  & 5  & 55085 & 50 & 55568* & 52* & 6642  & 89 & 6193  & 70  \\ \hline
5  & 283  & 21 & 103 & 12 & 25819 & 44 & 26744* & 35* & 27544 & 36 & 27289*& 35* \\ \hline
6  & 222  & 17 & 99  & 7  & 27035 & 68 & 27409* & 61* & 66    & 8  & 39    & 7   \\ \hline
7  & 9    & 4  & 9   & 4  & 8094  & 25 & 4948   & 28  & 4345  & 30 & 5169  & 34  \\ \hline
8  & 16   & 4  & 11  & 4  & 844   & 13 & 4      & 2   & 2707  & 24 & 2611* & 23* \\ \hline
9  & 21   & 7  & 18  & 6  & 299   & 19 & 287    & 19  & 622   & 22 & 210   & 16  \\ \noalign{\hrule height 1pt}
\end{tabular}}
\end{table}
